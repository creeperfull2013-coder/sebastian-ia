// app/server.js
import express from "express";
import fetch from "node-fetch";
import bodyParser from "body-parser";
import cors from "cors";

const app = express();
app.use(cors());
app.use(bodyParser.json());

// ðŸ”’ Token Hugging Face depuis les variables d'environnement
const HF_TOKEN = process.env.HF_TOKEN;
if (!HF_TOKEN) {
  console.error("âŒ HF_TOKEN non dÃ©fini. Ajoutez-le dans Render > Environment.");
}

const MODEL = "gpt-neo-2.7B"; // tu peux changer pour un autre modÃ¨le si besoin

// Fonction pour gÃ©nÃ©rer la rÃ©ponse IA
async function getAIResponse(prompt) {
  try {
    const response = await fetch(`https://api-inference.huggingface.co/models/${MODEL}`, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${HF_TOKEN}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({ inputs: prompt })
    });

    const data = await response.json();

    // VÃ©rifie si le modÃ¨le renvoie du texte
    if (data.error) {
      console.error("Hugging Face API Error:", data.error);
      return "DÃ©solÃ©, je n'ai pas compris.";
    }

    return data[0]?.generated_text || "DÃ©solÃ©, je n'ai pas compris.";
  } catch (err) {
    console.error("Erreur serveur:", err);
    return "Erreur serveur.";
  }
}

// Endpoint POST /chat
app.post("/chat", async (req, res) => {
  const { message } = req.body;
  if (!message) return res.json({ reply: "Erreur : message vide." });

  const reply = await getAIResponse(message);
  res.json({ reply });
});

// Serveur prÃªt
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`âœ… Serveur Hugging Face prÃªt sur http://localhost:${PORT}`));
